
'''
Pr√©sentation des mod√®les entra√Æn√©s et de leurs r√©sultats 
Analyse du meilleur mod√®le sur diff√©rents fichiers existants 
'''
import streamlit as st

st.title('Mod√®les entra√Æn√©s')
st.subheader("Int√©r√™t du deep learning")
st.markdown("""<div style="text-align: justify"> Les r√©sultats obtenus avec l'Isolation Forest et plus largement les algorithmes de classification, mettent en √©vidence 
qu'un changement de paradigme est n√©cessaire pour progresser vers un syst√®me de d√©tection performant.
Le recours √† des mod√®les de deep learning constitue une suite logique √† notre d√©marche,
en offrant une alternative capable de d√©passer les limitations structurelles des algorithmes classiques.
</div>""", unsafe_allow_html=True)
st.markdown("")
st.markdown("""<div style="text-align: justify"> Les mod√®les de deep learning, et notamment les r√©seaux de neurones convolutifs (CNN) 
ou les architectures audio pr√©-entra√Æn√©es comme Wav2Vec2, pr√©sentent plusieurs avantages d√©cisifs dans ce contexte :
</div>""", unsafe_allow_html=True)
with st.expander("üíª Apprentissage automatique des caract√©ristiques"):
st.caption("""Contrairement aux approches classiques qui n√©cessitent une extraction manuelle des features 
(moyennes de bandes fr√©quentielles, √©cart-types, etc.), les r√©seaux de neurones profonds apprennent 
directement des repr√©sentations pertinentes √† partir des donn√©es brutes. 
Cette capacit√© permet de capturer des patterns acoustiques complexes associ√©s aux crises, 
sans biais li√© au choix des descripteurs.""")
with st.expander("‚åõ Mod√©lisation de la dynamique temporelle"):
st.caption(""" En int√©grant des fen√™tres temporelles glissantes (2 secondes dans notre cas) 
et des architectures capables d'exploiter la continuit√© des signaux, 
les mod√®les profonds peuvent extraire des s√©quences temporelles significatives, 
l√† o√π les classifieurs classiques √©chouent √† capturer la variabilit√© inter- et intra-patients.""")
with st.expander("üîä Meilleure gestion du bruit"):
st.caption("""Les enregistrements utilis√©s comportent des artefacts sonores (bruits ambiants, √©changes verbaux, mouvements) 
susceptibles de perturber la d√©tection. Les mod√®les de deep learning, via leur capacit√© √† filtrer 
les informations non pertinentes, se montrent plus robustes √† ces perturbations, limitant les faux positifs.""")
with st.expander("üë©‚Äç‚öïÔ∏èG√©n√©ralisation aux nouveaux patients"):
st.caption(""" Gr√¢ce √† une phase de pr√©-entra√Ænement sur de larges corpus audio, des mod√®les comme Wav2Vec2 
peuvent √™tre fine-tun√©s sur des donn√©es sp√©cifiques (√©pilepsie) tout en conservant une bonne 
capacit√© de g√©n√©ralisation, ce qui est crucial dans le contexte de la variabilit√© interindividuelle.""")

st.badge("Premi√®re approche (Undersampling + Wav2Vec)", color='violet')
st.markdown("""<div style="text-align: justify"> Nous avons d'abord appliqu√© un undersampling sur nos donn√©es d√©s√©quilibr√©es. Cela nous a permis de r√©duire l'√©cart de pond√©ration de chaque classe, 
assurant que la classe minoritaire (crise) ait autant d'importance que la classe majoritaire (pas crise). Cela √©vite que le mod√®le privil√©gie la classe dominante et am√©liore la qualit√© de la classification.

Ensuite, nous avons fine-tun√© Wav2vec sur des donn√©es audio et l'avons directement utilis√© pour la classification.
</div>""", unsafe_allow_html=True)
st.markdown("")

st.badge("Deuxi√®me approche (Wav2Vec + GradientBoosting)", color='violet')

st.markdown("""<div style="text-align: justify">Dans notre deuxi√®me approche, Wav2Vec2 a servi √† extraire des caract√©ristiques audio, mais ensuite un autre mod√®le a √©t√© appliqu√© sur ces caract√©ristiques pour la classification.

Nous avons opt√© pour un Gradient Boosting Classifier, un mod√®le d'ensemble bas√© sur une succession d'arbres de d√©cision. Ce choix s'explique par sa capacit√© √† capturer des relations complexes et non lin√©aires dans les donn√©es, ainsi que sa robustesse face aux probl√®mes de classification d√©s√©quilibr√©e, tel que celui rencontr√© dans notre cas (√©pisodes de crises √©pileptiques vs segments non √©pileptiques).
Afin d'acc√©l√©rer l'ex√©cution de cette approche, nous avons √©galement appliqu√© une PCA (Analyse en Composantes Principales) sur les caract√©ristiques extraites par Wav2Vec2. Cela a permis de r√©duire la dimensionnalit√© des donn√©es tout en pr√©servant l'essentiel de l'information, facilitant ainsi l'entra√Ænement du mod√®le de Gradient Boosting.

</div>""", unsafe_allow_html=True)
st.markdown("")

st.badge("Troisi√®me approche (CNN)", color='violet')
st.markdown("""<div style="text-align: justify"> Afin d'explorer une alternative aux mod√®les pr√©-entra√Æn√©s de type Wav2Vec2, 
une troisi√®me approche bas√©e sur un r√©seau neuronal convolutionnel (CNN) Keras a √©t√© mise en ≈ìuvre.
Ce choix s'inscrit dans une tendance actuelle o√π les CNN sont de plus en plus utilis√©s pour l'analyse audio, et 
a √©t√© d√©velopp√©e pour la d√©tection des crises √©pileptiques √† partir de signaux audio. 

Cette m√©thode s'appuie sur la transformation des signaux acoustiques en spectrogrammes, 
qui constituent des repr√©sentations visuelles temps-fr√©quence bien adapt√©es √† l'apprentissage profond.

L'objectif ici est d'exploiter la capacit√© des CNN √† extraire automatiquement des motifs discriminants dans ces repr√©sentations spectrales, 
sans recourir √† des embeddings pr√©existants. Ce choix m√©thodologique offre une architecture plus l√©g√®re et contr√¥lable, 
notamment pour des cas o√π les ressources de calcul sont limit√©es ou lorsque l'on souhaite une personnalisation du mod√®le √† un domaine sp√©cifique.
</div>""", unsafe_allow_html=True)

st.image("images/5_pipeline.png","Pipeline global de traitement mis en oeuvre dans cette troisi√®me approche")
st.markdown("")
st.subheader("Analyse comparative des approches et choix du mod√®le")
st.image("images/5_deep_synthesis.png","""Strat√©gies explor√©es dans nos recherches incluant du deep learning. Sont exclues de ce diagrammes les recherches
concernant les classifieurs puisque ces recherches n'ont pas port√© leurs fruits et les m√©thodes de pens√©e & concepts ont √©t√© repris et appliqu√©s au deep learning.""")



st.badge("Analyse comparative des approches", color='violet')
st.markdown("""<div style="text-align: justify"> L'objectif principal de ce projet √©tait d'explorer diff√©rentes strat√©gies 
de classification pour la d√©tection de crises d'√©pilepsie √† partir d'enregistrements audio, 
en tenant compte du d√©s√©quilibre intrins√®que des donn√©es. Trois grandes familles d'approches ont √©t√© test√©es : </div>""", unsafe_allow_html=True)
st.markdown("* Des mod√®les de machine learning classiques √† partir de descripteurs statistiques")
st.markdown("* Des mod√®les pr√© entra√Æn√©s de type Wav2Vec2")
st.markdown("* Des r√©seaux de neurones convolutifs (CNN)")
st.markdown("""<div style="text-align: justify"> Chaque approche a √©t√© √©valu√©e selon des m√©triques standard (pr√©cision, rappel, F1-score), 
avec un focus particulier sur la classe minoritaire correspondant aux √©pisodes de crise.</div>""", unsafe_allow_html=True)
st.markdown("")

with st.expander("üíª Approches par Machine Learning supervis√© et non supervis√©"):
st.markdown("""<div style="text-align: justify"> Une premi√®re s√©rie de pipelines a √©t√© mise en ≈ìuvre √† partir de descripteurs 
statistiques simples (moyenne et √©cart-type glissants), suivis d'une r√©duction de dimensionnalit√© par ACP (PCA). 
Plusieurs variantes ont √©t√© compar√©es :
</div>""", unsafe_allow_html=True)
st.markdown("* PCA + Gradient Boosting")
st.markdown("* PCA +¬† Classification par centro√Ødes + Gradient Boosting")
st.markdown("* PCA + Isolation Forest (avec un seuil d'anomalie fix√© √† 5 %)")
st.markdown("""<div style="text-align: justify"> Les performances globales de ces mod√®les supervis√©s classiques se sont r√©v√©l√©es modestes, 
en particulier pour la d√©tection des √©pisodes de crise. L'approche semi-supervis√©e par Isolation Forest a toutefois 
montr√© de meilleures capacit√©s de rappel, en identifiant efficacement certains segments audio atypiques. 
Cependant, sa d√©pendance √† un param√©trage n√©cessitant une estimation a priori du taux de crises limite 
sa g√©n√©ralisation √† des contextes r√©els.</div>""", unsafe_allow_html=True)
st.markdown("")

with st.expander("üîä Mod√®le Wav2Vec2 avec strat√©gies d'√©quilibrage"):
st.markdown("""<div style="text-align: justify"> Le mod√®le pr√© entra√Æn√© Wav2Vec2 a √©t√© test√© avec des segments audio de 1 et 2 secondes, 
en appliquant une strat√©gie d'undersampling pour compenser le d√©s√©quilibre de classes. 
Pour des segments d'1 seconde, la pr√©cision globale atteignait 0.89, mais la d√©tection des crises 
restait faible (F1-score = 0.36). Avec des segments de 2 secondes, le F1-score pour la classe "crise" montait √† 0.54, 
sugg√©rant une meilleure captation des dynamiques acoustiques sp√©cifiques.</div>""", unsafe_allow_html=True)
st.markdown("")
st.markdown("""<div style="text-align: justify"> Une variante supervis√©e, combinant les embeddings Wav2Vec2 
√† un classificateur Gradient Boosting entra√Æn√© par lot sur GPU, n'a pas permis d'am√©lioration significative. 
Le mod√®le restait tr√®s performant sur la classe majoritaire (F1-score = 0.98) mais quasiment aveugle 
aux √©pisodes de crise (F1-score = 0.10), illustrant la difficult√© √† √©quilibrer la classification avec cette architecture.
</div>""", unsafe_allow_html=True)
st.markdown("")

with st.expander("üß† R√©seau de Neurones Convolutif (CNN)"):
st.markdown("""<div style="text-align: justify"> L'approche par CNN s'est d√©marqu√©e par des performances nettement 
plus √©quilibr√©es, et ce pour les deux dur√©es de segments test√©es. Pour des segments d'1 seconde, 
le mod√®le atteignait un F1-score de 0.70 pour la classe "crise", avec un rappel de 0.59. 
En passant √† des segments de 2 secondes, les performances s'am√©liorent encore (F1-score = 0.79 ; rappel = 0.72), 
traduisant une meilleure captation des motifs temporels caract√©ristiques des √©pisodes. </div>""", unsafe_allow_html=True)
st.markdown("")
st.markdown("""<div style="text-align: justify"> L'analyse a √©galement montr√© que des fen√™tres trop longues (10 secondes) 
d√©gradent les performances tout en alourdissant consid√©rablement la charge computationnelle. 
Un compromis optimal a √©t√© trouv√© avec une fen√™tre de 2 secondes, 
suffisante pour extraire les dynamiques pertinentes tout en restant adapt√©e √† un traitement efficace. Cette fen√™tre temporelle est d'ailleurs mise en avant dans la litt√©rature scientifique.</div>""", unsafe_allow_html=True)
st.markdown("")

st.badge("Choix du mod√®le", color='green')
st.markdown("""<div style="text-align: justify"> √Ä l'issue de cette analyse, le mod√®le CNN entra√Æn√© sur des segments audio 
de 2 secondes a √©t√© retenu comme la solution la plus pertinente pour la d√©tection automatique des crises 
√©pileptiques √† partir du signal vocal.</div>""", unsafe_allow_html=True)
st.markdown("")
st.markdown("""<div style="text-align: justify"> Les approches classiques bas√©es sur des descripteurs statistiques, 
m√™me enrichies de techniques comme PCA ou Isolation Forest, ont montr√© une sensibilit√© insuffisante 
√† la classe minoritaire et une capacit√© de g√©n√©ralisation limit√©e. Les architectures Wav2Vec2 
ont offert des repr√©sentations audio riches, mais n'ont pas permis d'am√©liorer la d√©tection 
des crises de mani√®re satisfaisante, m√™me apr√®s √©quilibrage ou transformation des embeddings.
</div>""", unsafe_allow_html=True)
st.markdown("")
st.markdown("""<div style="text-align: justify"> Le mod√®le CNN, en revanche, s'est distingu√© 
par sa capacit√© √† d√©tecter efficacement les √©v√©nements rares, avec un excellent compromis 
entre rappel, F1-score, robustesse au d√©s√©quilibre de classes et co√ªt computationnel. 
Il constitue donc la base retenue pour les prochaines phases du projet, notamment 
en vue d'une int√©gration dans un syst√®me embarqu√© ou une application clinique.
</div>""", unsafe_allow_html=True)
st.markdown("""<div style="text-align: justify"> Il serait pertinent de tester √† nouveau ses approches sur des volumes de donn√©es plus importants incluant entre autres de multiples crises pour un patient donn√©.
Cela permettrait de mieux √©valuer la capacit√© de g√©n√©ralisation du mod√®le et d'optimiser ses performances sur des donn√©es r√©elles. 
De plus, l'int√©gration de techniques d'augmentation de donn√©es pourrait √©galement √™tre envisag√©e pour enrichir le jeu de donn√©es d'entra√Ænement et am√©liorer la robustesse du mod√®le.
</div>""", unsafe_allow_html=True)
