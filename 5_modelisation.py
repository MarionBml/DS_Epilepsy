'''
Pr√©sentation des mod√®les entra√Æn√©s et de leurs r√©sultats 
Analyse du meilleur mod√®le sur diff√©rents fichiers existants 
'''
import streamlit as st

st.title('Mod√®les entra√Æn√©s')
st.subheader("Int√©r√™t du deep learning")
st.markdown("""<div style="text-align: justify"> Les r√©sultats obtenus avec l‚ÄôIsolation Forest mettent en √©vidence 
            qu‚Äôun changement de paradigme est n√©cessaire pour progresser vers un syst√®me de d√©tection performant. 
            Le recours √† des mod√®les de deep learning constitue une suite logique √† notre d√©marche, 
            en offrant une alternative capable de d√©passer les limitations structurelles des algorithmes classiques.
</div>""", unsafe_allow_html=True)
st.markdown("")
st.markdown("""<div style="text-align: justify"> Les mod√®les de deep learning, et notamment les r√©seaux de neurones convolutifs (CNN) 
            ou les architectures audio pr√©-entra√Æn√©es comme Wav2Vec2, pr√©sentent plusieurs avantages d√©cisifs dans ce contexte :
</div>""", unsafe_allow_html=True)
with st.expander("üíª Apprentissage automatique des caract√©ristiques"):
    st.caption("""Contrairement aux approches classiques qui n√©cessitent une extraction manuelle des features 
               (moyennes de bandes fr√©quentielles, √©cart-types, etc.), les r√©seaux de neurones profonds apprennent 
               directement des repr√©sentations pertinentes √† partir des donn√©es brutes. 
               Cette capacit√© permet de capturer des patterns acoustiques complexes associ√©s aux crises, 
               sans biais li√© au choix des descripteurs.""")
with st.expander("‚åõ Mod√©lisation de la dynamique temporelle"):
    st.caption(""" En int√©grant des fen√™tres temporelles glissantes (4 secondes dans notre cas) 
               et des architectures capables d‚Äôexploiter la continuit√© des signaux, 
               les mod√®les profonds peuvent extraire des s√©quences temporelles significatives, 
               l√† o√π les classifieurs classiques √©chouent √† capturer la variabilit√© inter- et intra-patients.""")
with st.expander("üîä Meilleure gestion du bruit"):
    st.caption("""Les enregistrements utilis√©s comportent des artefacts sonores (bruits ambiants, √©changes verbaux, mouvements) 
               susceptibles de perturber la d√©tection. Les mod√®les de deep learning, via leur capacit√© √† filtrer 
               les informations non pertinentes, se montrent plus robustes √† ces perturbations, limitant les faux positifs.""")
with st.expander("üë©‚Äç‚öïÔ∏èG√©n√©ralisation aux nouveaux patients"):
    st.caption(""" Gr√¢ce √† une phase de pr√©-entra√Ænement sur de larges corpus audio, des mod√®les comme Wav2Vec2 
               peuvent √™tre fine-tun√©s sur des donn√©es sp√©cifiques (√©pilepsie) tout en conservant une bonne 
               capacit√© de g√©n√©ralisation, ce qui est crucial dans le contexte de la variabilit√© interindividuelle.""")
    
st.badge("Premi√®re approche", color='violet')
st.badge("Deuxi√®me approche", color='violet')
st.badge("Troisi√®me approche", color='violet')

st.subheader("Analyse comparative des approches et choix du mod√®le")
st.markdown("""<div style="text-align: justify"> L‚Äôobjectif principal de ce projet √©tait d‚Äôexplorer diff√©rentes strat√©gies 
            de classification pour la d√©tection de crises d‚Äô√©pilepsie √† partir d‚Äôenregistrements audio, 
            en tenant compte du d√©s√©quilibre intrins√®que des donn√©es. Trois grandes familles d‚Äôapproches ont √©t√© test√©es : </div>""", unsafe_allow_html=True)
st.markdown("* Des mod√®les de machine learning classiques √† partir de descripteurs statistiques")
st.markdown("* Des mod√®les pr√© entra√Æn√©s de type Wav2Vec2")
st.markdown("* Des r√©seaux de neurones convolutifs (CNN)")
st.markdown("""<div style="text-align: justify"> Chaque approche a √©t√© √©valu√©e selon des m√©triques standard (pr√©cision, rappel, F1-score), 
            avec un focus particulier sur la classe minoritaire correspondant aux √©pisodes de crise.</div>""", unsafe_allow_html=True)
st.markdown("")

st.badge("Approches par Machine Learning supervis√© et non supervis√©", color='blue')
st.markdown("""<div style="text-align: justify"> Une premi√®re s√©rie de pipelines a √©t√© mise en ≈ìuvre √† partir de descripteurs 
            statistiques simples (moyenne et √©cart-type glissants), suivis d‚Äôune r√©duction de dimensionnalit√© par ACP (PCA). 
            Plusieurs variantes ont √©t√© compar√©es :
</div>""", unsafe_allow_html=True)
st.markdown("* PCA + Gradient Boosting")
st.markdown("* PCA +  Classification par centro√Ødes + Gradient Boosting")
st.markdown("* PCA + Isolation Forest (avec un seuil d‚Äôanomalie fix√© √† 5 %)")
st.markdown("""<div style="text-align: justify"> Les performances globales de ces mod√®les supervis√©s classiques se sont r√©v√©l√©es modestes, 
            en particulier pour la d√©tection des √©pisodes de crise. L‚Äôapproche semi-supervis√©e par Isolation Forest a toutefois 
            montr√© de meilleures capacit√©s de rappel, en identifiant efficacement certains segments audio atypiques. 
            Cependant, sa d√©pendance √† un param√©trage n√©cessitant une estimation a priori du taux de crises limite 
            sa g√©n√©ralisation √† des contextes r√©els.
</div>""", unsafe_allow_html=True)
st.markdown("")

st.badge("Mod√®le Wav2Vec2 avec strat√©gies d‚Äô√©quilibrage", color='blue')
st.markdown("""<div style="text-align: justify"> Le mod√®le pr√© entra√Æn√© Wav2Vec2 a √©t√© test√© avec des segments audio de 1 et 2 secondes, 
            en appliquant une strat√©gie d‚Äôundersampling pour compenser le d√©s√©quilibre de classes. 
            Pour des segments d‚Äô1 seconde, la pr√©cision globale atteignait 0.89, mais la d√©tection des crises 
            restait faible (F1-score = 0.36). Avec des segments de 2 secondes, le F1-score pour la classe "crise" montait √† 0.54, 
            sugg√©rant une meilleure captation des dynamiques acoustiques sp√©cifiques.
</div>""", unsafe_allow_html=True)
st.markdown("")
st.markdown("""<div style="text-align: justify"> Une variante supervis√©e, combinant les embeddings Wav2Vec2 
            √† un classificateur Gradient Boosting entra√Æn√© par lot sur GPU, n‚Äôa pas permis d‚Äôam√©lioration significative. 
            Le mod√®le restait tr√®s performant sur la classe majoritaire (F1-score = 0.98) mais quasiment aveugle 
            aux √©pisodes de crise (F1-score = 0.10), illustrant la difficult√© √† √©quilibrer la classification avec cette architecture.
</div>""", unsafe_allow_html=True)
st.markdown("")

st.badge("R√©seau de Neurones Convolutif (CNN)", color='blue')
st.markdown("""<div style="text-align: justify"> L‚Äôapproche par CNN s‚Äôest d√©marqu√©e par des performances nettement 
            plus √©quilibr√©es, et ce pour les deux dur√©es de segments test√©es. Pour des segments d‚Äô1 seconde, 
            le mod√®le atteignait un F1-score de 0.70 pour la classe "crise", avec un rappel de 0.59. 
            En passant √† des segments de 2 secondes, les performances s'am√©liorent encore (F1-score = 0.79 ; rappel = 0.72), 
            traduisant une meilleure captation des motifs temporels caract√©ristiques des √©pisodes.
</div>""", unsafe_allow_html=True)
st.markdown("")
st.markdown("""<div style="text-align: justify"> L‚Äôanalyse a √©galement montr√© que des fen√™tres trop longues (10 secondes) 
            d√©gradent les performances tout en alourdissant consid√©rablement la charge computationnelle. 
            Un compromis optimal a √©t√© trouv√© avec une fen√™tre de 2 secondes, 
            suffisante pour extraire les dynamiques pertinentes tout en restant adapt√©e √† un traitement efficace.
</div>""", unsafe_allow_html=True)
st.markdown("")

st.badge("Choix du mod√®le", color='green')
st.markdown("""<div style="text-align: justify"> √Ä l‚Äôissue de cette analyse, le mod√®le CNN entra√Æn√© sur des segments audio 
            de 2 secondes a √©t√© retenu comme la solution la plus pertinente pour la d√©tection automatique des crises 
            √©pileptiques √† partir du signal vocal.</div>""", unsafe_allow_html=True)
st.markdown("")
st.markdown("""<div style="text-align: justify"> Les approches classiques bas√©es sur des descripteurs statistiques, 
            m√™me enrichies de techniques comme PCA ou Isolation Forest, ont montr√© une sensibilit√© insuffisante 
            √† la classe minoritaire et une capacit√© de g√©n√©ralisation limit√©e. Les architectures Wav2Vec2 
            ont offert des repr√©sentations audio riches, mais n‚Äôont pas permis d‚Äôam√©liorer la d√©tection 
            des crises de mani√®re satisfaisante, m√™me apr√®s √©quilibrage ou transformation des embeddings.
</div>""", unsafe_allow_html=True)
st.markdown("")
st.markdown("""<div style="text-align: justify"> Le mod√®le CNN, en revanche, s‚Äôest distingu√© 
            par sa capacit√© √† d√©tecter efficacement les √©v√©nements rares, avec un excellent compromis 
            entre rappel, F1-score, robustesse au d√©s√©quilibre de classes et co√ªt computationnel. 
            Il constitue donc la base retenue pour les prochaines phases du projet, notamment 
            en vue d‚Äôune int√©gration dans un syst√®me embarqu√© ou une application clinique.
</div>""", unsafe_allow_html=True)
