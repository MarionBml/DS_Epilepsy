'''
PrÃ©sentation des modÃ¨les entraÃ®nÃ©s et de leurs rÃ©sultats 
Analyse du meilleur modÃ¨le sur diffÃ©rents fichiers existants 
'''
import streamlit as st

st.title('ModÃ¨les entraÃ®nÃ©s')
st.subheader("IntÃ©rÃªt du deep learning")
st.markdown("""<div style="text-align: justify"> Les rÃ©sultats obtenus avec lâ€™Isolation Forest mettent en Ã©vidence 
            quâ€™un changement de paradigme est nÃ©cessaire pour progresser vers un systÃ¨me de dÃ©tection performant. 
            Le recours Ã  des modÃ¨les de deep learning constitue une suite logique Ã  notre dÃ©marche, 
            en offrant une alternative capable de dÃ©passer les limitations structurelles des algorithmes classiques.
</div>""", unsafe_allow_html=True)
st.markdown("")
st.markdown("""<div style="text-align: justify"> Les modÃ¨les de deep learning, et notamment les rÃ©seaux de neurones convolutifs (CNN) 
            ou les architectures audio prÃ©-entraÃ®nÃ©es comme Wav2Vec2, prÃ©sentent plusieurs avantages dÃ©cisifs dans ce contexte :
</div>""", unsafe_allow_html=True)
with st.expander("ğŸ’» Apprentissage automatique des caractÃ©ristiques"):
    st.caption("""Contrairement aux approches classiques qui nÃ©cessitent une extraction manuelle des features 
               (moyennes de bandes frÃ©quentielles, Ã©cart-types, etc.), les rÃ©seaux de neurones profonds apprennent 
               directement des reprÃ©sentations pertinentes Ã  partir des donnÃ©es brutes. 
               Cette capacitÃ© permet de capturer des patterns acoustiques complexes associÃ©s aux crises, 
               sans biais liÃ© au choix des descripteurs.""")
with st.expander("âŒ› ModÃ©lisation de la dynamique temporelle"):
    st.caption(""" En intÃ©grant des fenÃªtres temporelles glissantes (4 secondes dans notre cas) 
               et des architectures capables dâ€™exploiter la continuitÃ© des signaux, 
               les modÃ¨les profonds peuvent extraire des sÃ©quences temporelles significatives, 
               lÃ  oÃ¹ les classifieurs classiques Ã©chouent Ã  capturer la variabilitÃ© inter- et intra-patients.""")
with st.expander("ğŸ”Š Meilleure gestion du bruit"):
    st.caption("""Les enregistrements utilisÃ©s comportent des artefacts sonores (bruits ambiants, Ã©changes verbaux, mouvements) 
               susceptibles de perturber la dÃ©tection. Les modÃ¨les de deep learning, via leur capacitÃ© Ã  filtrer 
               les informations non pertinentes, se montrent plus robustes Ã  ces perturbations, limitant les faux positifs.""")
with st.expander("ğŸ‘©â€âš•ï¸GÃ©nÃ©ralisation aux nouveaux patients"):
    st.caption(""" GrÃ¢ce Ã  une phase de prÃ©-entraÃ®nement sur de larges corpus audio, des modÃ¨les comme Wav2Vec2 
               peuvent Ãªtre fine-tunÃ©s sur des donnÃ©es spÃ©cifiques (Ã©pilepsie) tout en conservant une bonne 
               capacitÃ© de gÃ©nÃ©ralisation, ce qui est crucial dans le contexte de la variabilitÃ© interindividuelle.""")
    
st.subheader("PremiÃ¨re approche")
st.subheader("DeuxiÃ¨me approche")
st.subheader("TroisiÃ¨me approche")
